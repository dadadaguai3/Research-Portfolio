#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¢„ç®—AIåˆ†æç³»ç»Ÿ - Kimiç‰ˆæœ¬ (Demo)
ä½¿ç”¨Kimiçš„æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½ï¼Œç›´æ¥ä¸Šä¼ Excelã€PDFç­‰æ–‡ä»¶è¿›è¡ŒAIåˆ†æ
"""

import os
import sys
import time
import re
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional
import json

# ==============================================================================
# ğŸ¯ é…ç½®åŒºåŸŸ
# ==============================================================================

# Kimi APIå¯†é’¥
# å»ºè®®æ–¹å¼ï¼šå°†Keyä¿å­˜åœ¨ç¯å¢ƒå˜é‡ KIMI_API_KEY ä¸­ï¼Œæˆ–åœ¨ä¸‹æ–¹å¼•å·å†…å¡«å…¥ä½ çš„Key
# âš ï¸ æ³¨æ„ï¼šä¸Šä¼ GitHubå‰è¯·åŠ¡å¿…ç¡®ä¿æ­¤å¤„ä¸ºç©ºæˆ–ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼
KIMI_API_KEY = os.getenv("KIMI_API_KEY", "your_api_key_here")

# è¾“å‡ºç›®å½• (ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œæ–¹ä¾¿æ¼”ç¤º)
OUTPUT_DIR = os.path.join(os.getcwd(), "analysis_results")

# è¦åˆ†æçš„æ–‡ä»¶å¤¹åˆ—è¡¨ (ç¤ºä¾‹è·¯å¾„)
# å®é™…ä½¿ç”¨æ—¶è¯·ä¿®æ”¹ä¸ºåŒ…å«è´¢æ”¿æ•°æ®çš„æ–‡ä»¶å¤¹è·¯å¾„
FOLDERS_TO_ANALYZE = [
    r"./data/sample_province/city_a",
    r"./data/sample_province/city_b",
    # r"C:\Users\YourName\Data\RealData\CityC"
]

# æå–çš„è´¢æ”¿æŒ‡æ ‡
PARAMETERS = [
    "è´¢æ”¿äº‹åŠ¡",
    "ç¨æ”¶äº‹åŠ¡",
    "å®¡è®¡äº‹åŠ¡",
    "è´¢æ”¿äº‹åŠ¡â€”â€”ä¿¡æ¯åŒ–å»ºè®¾",
    "ç¨æ”¶äº‹åŠ¡â€”â€”ä¿¡æ¯åŒ–å»ºè®¾",
    "å®¡è®¡äº‹åŠ¡â€”â€”ä¿¡æ¯åŒ–å»ºè®¾",
]

# Kimiæ¨¡å‹é…ç½®
KIMI_MODEL = "kimi-k2-turbo-preview"

# æ–‡ä»¶æ•°é‡é™åˆ¶é…ç½®
FILE_LIMIT_CONFIG = {
    "MAX_FILES": 1000,  # Kimiå•ç”¨æˆ·æœ€å¤š1000ä¸ªæ–‡ä»¶
    "MAX_SIZE_MB": 100,  # å•æ–‡ä»¶æœ€å¤§100MB
    "MAX_TOTAL_SIZE_GB": 10,  # æ€»å®¹é‡æœ€å¤§10GB
    "WARNING_THRESHOLD": 0.8,  # æŠ¥è­¦é˜ˆå€¼
    "ACTION_ON_EXCEED": "skip",  # "skip"è·³è¿‡ æˆ– "stop"ä¸­æ–­
    "COMPRESS_LARGE_PDF": True,  # æ˜¯å¦å‹ç¼©å¤§PDFæ–‡ä»¶
    "PDF_COMPRESS_THRESHOLD": 5.0,
    "PDF_COMPRESS_QUALITY": "medium",
}

# æ˜¯å¦åœ¨åˆ†æå®Œæˆååˆ é™¤ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆèŠ‚çœç©ºé—´ï¼‰
DELETE_UPLOADED_FILES_AFTER_ANALYSIS = True

# APIé€Ÿç‡é™åˆ¶é…ç½®ï¼ˆæ ¹æ®Tier1è´¦å·é™åˆ¶ï¼‰
RATE_LIMIT_CONFIG = {
    "TPM_LIMIT": 2000000,
    "RPM_LIMIT": 200,
    "RETRY_DELAY": 30,
    "MAX_RETRIES": 3,
    "ENABLE_RETRY": True,
}

# ==============================================================================
# ğŸš€ è¿è¡Œç¨‹åº
# ==============================================================================

try:
    from openai import OpenAI
    import pandas as pd
    # æ³¨æ„ï¼šå¦‚æœä½¿ç”¨äº†å‹ç¼©åŠŸèƒ½ï¼Œå¯èƒ½è¿˜éœ€è¦å¯¼å…¥å…¶ä»–åº“
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {e}")
    print("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ä¾èµ–:")
    print("pip install openai pandas")
    sys.exit(1)


class KimiBudgetAnalyzer:
    """åŸºäºKimiçš„é¢„ç®—åˆ†æå™¨"""

    def __init__(self):
        self.api_key = KIMI_API_KEY
        if "your_api_key_here" in self.api_key or not self.api_key:
            print("âŒ é”™è¯¯ï¼šæœªé…ç½®æœ‰æ•ˆ API Keyã€‚è¯·åœ¨ä»£ç ä¸­é…ç½®æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ KIMI_API_KEYã€‚")
            sys.exit(1)

        self.output_dir = OUTPUT_DIR
        self.parameters = PARAMETERS
        self.model = KIMI_MODEL
        self.file_limit_config = FILE_LIMIT_CONFIG

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)

        self.client = None
        self.uploaded_files = []
        self.total_file_count = 0
        self.total_size_bytes = 0
        self.rate_limit_config = RATE_LIMIT_CONFIG
        self.last_request_time = 0
        self.conversation_history = {}
        self.compressed_files = []

    def initialize_client(self):
        """åˆå§‹åŒ–Kimiå®¢æˆ·ç«¯"""
        try:
            self.client = OpenAI(
                api_key=self.api_key,
                base_url="https://api.moonshot.cn/v1",
            )
            print("âœ… Kimiå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ Kimiå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def get_current_file_stats(self) -> Dict[str, Any]:
        """è·å–å½“å‰æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "uploaded_count": len(self.uploaded_files),
            "total_size_mb": self.total_size_bytes / (1024 * 1024),
            "max_files": self.file_limit_config["MAX_FILES"],
            "max_size_mb": self.file_limit_config["MAX_SIZE_MB"],
            "max_total_gb": self.file_limit_config["MAX_TOTAL_SIZE_GB"],
            "remaining_files": self.file_limit_config["MAX_FILES"] - len(self.uploaded_files),
            "remaining_size_mb": (self.file_limit_config["MAX_TOTAL_SIZE_GB"] * 1024) - (
                        self.total_size_bytes / (1024 * 1024)),
        }

    def initialize_conversation(self, city_name: str):
        if city_name not in self.conversation_history:
            base_system_prompt = """ä½ æ˜¯Kimiï¼Œç”± Moonshot AI æä¾›çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚"""
            self.conversation_history[city_name] = [
                {"role": "system", "content": base_system_prompt}
            ]
            # print(f"âœ… åˆå§‹åŒ– {city_name} çš„å¯¹è¯ä¸Šä¸‹æ–‡") # å‡å°‘æ—¥å¿—è¾“å‡º

    def get_conversation_messages(self, city_name: str, max_history: int = 20) -> List[Dict]:
        if city_name not in self.conversation_history:
            self.initialize_conversation(city_name)
        messages = self.conversation_history[city_name]
        if len(messages) > max_history + 1:
            system_msg = messages[0]
            recent_messages = messages[-max_history:]
            self.conversation_history[city_name] = [system_msg] + recent_messages
            messages = self.conversation_history[city_name]
        return messages.copy()

    def add_to_conversation(self, city_name: str, message: Dict[str, str]):
        if city_name not in self.conversation_history:
            self.initialize_conversation(city_name)
        self.conversation_history[city_name].append(message)
        if len(self.conversation_history[city_name]) > 30:
            system_msg = self.conversation_history[city_name][0]
            recent_messages = self.conversation_history[city_name][-29:]
            self.conversation_history[city_name] = [system_msg] + recent_messages

    def check_file_limits(self, file_count: int, file_size_mb: float) -> tuple[bool, str]:
        stats = self.get_current_file_stats()
        if file_size_mb > self.file_limit_config["MAX_SIZE_MB"]:
            return False, f"æ–‡ä»¶å¤§å° {file_size_mb:.1f}MB è¶…è¿‡é™åˆ¶"
        if stats["uploaded_count"] + file_count > self.file_limit_config["MAX_FILES"]:
            return False, f"æ–‡ä»¶æ•°é‡å°†è¾¾åˆ°é™åˆ¶"
        new_total_size = stats["total_size_mb"] + file_size_mb
        if new_total_size > self.file_limit_config["MAX_TOTAL_SIZE_GB"] * 1024:
            return False, f"æ€»å®¹é‡å°†è¾¾åˆ°é™åˆ¶"
        return True, "æ£€æŸ¥é€šè¿‡"

    def handle_limit_exceeded(self, reason: str, file_info: Dict[str, Any] = None) -> bool:
        action = self.file_limit_config["ACTION_ON_EXCEED"]
        print(f"ğŸš¨ é™åˆ¶è­¦å‘Š: {reason} -> æ‰§è¡Œ: {action}")
        return True if action == "skip" else False

    def handle_rate_limit(self, retry_count: int = 0) -> bool:
        if not self.rate_limit_config["ENABLE_RETRY"] or retry_count >= self.rate_limit_config["MAX_RETRIES"]:
            return False
        delay = self.rate_limit_config["RETRY_DELAY"]
        print(f"â° è§¦å‘é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {delay} ç§’åé‡è¯•...")
        time.sleep(delay)
        return True

    def upload_file(self, file_path: str) -> Optional[str]:
        try:
            file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
            file_name = os.path.basename(file_path)

            # PDFå‹ç¼©é€»è¾‘å ä½ (ä¿ç•™ç»“æ„ï¼Œç®€åŒ–ä¾èµ–æ£€æŸ¥)
            is_compressed = False
            # ... (æ­¤å¤„ä¿ç•™åŸæœ‰å‹ç¼©é€»è¾‘ç»“æ„ï¼Œä¸ºä»£ç ç®€æ´ç•¥å»å…·ä½“å®ç°ç»†èŠ‚)

            can_upload, reason = self.check_file_limits(1, file_size_mb)
            if not can_upload:
                if not self.handle_limit_exceeded(reason): return None
                return "skipped"

            print(f"ğŸ“¤ ä¸Šä¼ ä¸­: {file_name}...")
            file_object = self.client.files.create(file=Path(file_path), purpose="file-extract")

            self.uploaded_files.append({
                "id": file_object.id, "name": file_name, "size_mb": file_size_mb,
                "id_compressed": is_compressed
            })
            self.total_file_count += 1
            self.total_size_bytes += os.path.getsize(file_path)
            return file_object.id
        except Exception as e:
            print(f"âŒ ä¸Šä¼ å¤±è´¥ {os.path.basename(file_path)}: {e}")
            return None

    def upload_files_batch(self, file_paths: List[str]) -> List[str]:
        uploaded_ids = []
        for path in file_paths:
            fid = self.upload_file(path)
            if fid and fid != "skipped": uploaded_ids.append(fid)
        return uploaded_ids

    def analyze_with_kimi(self, file_ids: List[str], city_name: str, year: str, description: str = "") -> Optional[
        Dict[str, Any]]:
        retry_count = 0
        while retry_count <= self.rate_limit_config["MAX_RETRIES"]:
            try:
                print(f"ğŸ¤– AIåˆ†æä¸­: {city_name} {year} ({len(file_ids)} files)")
                messages = self.get_conversation_messages(city_name)

                # ä¼˜åŒ–: ä»…åœ¨æœ‰æ–‡ä»¶IDæ—¶å°è¯•è·å–å†…å®¹
                valid_files = 0
                for file_id in file_ids:
                    try:
                        content = self.client.files.content(file_id=file_id).text
                        messages.append({"role": "system", "content": content})
                        valid_files += 1
                    except:
                        pass

                if valid_files == 0: return None

                system_prompt = f"""ä½ æ˜¯è´¢æ”¿ä¸“å®¶ã€‚è¯·ä»æ–‡ä»¶ä¸­æå–{city_name}{year}å¹´çš„å†³ç®—æ•°ï¼š
{chr(10).join(self.parameters)}
è¯·ä»¥JSONæ ¼å¼è¾“å‡ºï¼Œkeyä¸ºæŒ‡æ ‡åï¼Œvalueä¸ºæ•°å€¼(ä¸‡å…ƒ)ï¼Œæœªæ‰¾åˆ°å¡«"æœªæ‰¾åˆ°"ã€‚"""

                messages.append({"role": "system", "content": system_prompt})
                messages.append({"role": "user", "content": f"åˆ†æ{city_name}{year}å¹´æ•°æ®å¹¶æå–æŒ‡æ ‡ã€‚"})

                completion = self.client.chat.completions.create(
                    model=self.model, messages=messages, temperature=0.1,
                    response_format={"type": "json_object"}
                )

                self.last_request_time = time.time()
                ai_result = completion.choices[0].message.content.strip()

                self.add_to_conversation(city_name, messages[-1])  # User
                self.add_to_conversation(city_name, {"role": "assistant", "content": ai_result})

                return {"ai_result": ai_result, "valid_files": valid_files}

            except Exception as e:
                if "rate limit" in str(e).lower():
                    if self.handle_rate_limit(retry_count):
                        retry_count += 1
                        continue
                print(f"âŒ åˆ†æå‡ºé”™: {e}")
                return None
        return None

    def parse_ai_result(self, ai_data: Dict[str, Any], city_name: str, year: str) -> Optional[Dict[str, Any]]:
        if not ai_data: return None
        result = {"å¹´ä»½": year, "åŸå¸‚": city_name, "çŠ¶æ€": "æˆåŠŸ"}
        try:
            data = json.loads(ai_data["ai_result"])
            for param in self.parameters:
                result[param] = data.get(param, "æœªæ‰¾åˆ°")
        except:
            result["çŠ¶æ€"] = "è§£æå¤±è´¥"
            for param in self.parameters: result[param] = "è§£æå¤±è´¥"
        return result

    def cleanup_uploaded_files(self):
        if not DELETE_UPLOADED_FILES_AFTER_ANALYSIS: return
        print("ğŸ§¹ æ¸…ç†äº‘ç«¯æ–‡ä»¶...")
        for f in self.uploaded_files:
            try:
                self.client.files.delete(file_id=f["id"])
            except:
                pass

    def analyze_folder(self, folder_path: str) -> Optional[List[Dict[str, Any]]]:
        folder_name = os.path.basename(folder_path)
        if not os.path.exists(folder_path):
            print(f"â„¹ï¸ è·¯å¾„ä¸å­˜åœ¨(æ¼”ç¤ºæ¨¡å¼): {folder_path}")
            return None

        # ç®€åŒ–çš„æ–‡ä»¶å¤¹æ‰«æé€»è¾‘
        results = []
        # æ­¤å¤„çœç•¥äº†å¤æ‚çš„é€’å½’æ‰«æï¼Œå®é™…è¿è¡Œæ—¶è¯·ç¡®ä¿ç›®å½•ç»“æ„æ­£ç¡®
        # ...
        return results

    def save_results(self, results: List[Dict[str, Any]], folder_name: str = None) -> Optional[str]:
        if not results: return None
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{folder_name or 'Analysis'}_{timestamp}.xlsx"
        path = os.path.join(self.output_dir, filename)
        try:
            pd.DataFrame(results).to_excel(path, index=False)
            print(f"ğŸ’¾ ä¿å­˜æˆåŠŸ: {path}")
            return path
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            return None


def main():
    print("ğŸ¯ é¢„ç®—AIåˆ†æç³»ç»Ÿ - Kimi Demo")

    analyzer = KimiBudgetAnalyzer()
    if not analyzer.initialize_client(): return

    all_results = []
    for folder in FOLDERS_TO_ANALYZE:
        res = analyzer.analyze_folder(folder)
        if res: all_results.extend(res)

    analyzer.cleanup_uploaded_files()
    print("Done.")


if __name__ == "__main__":
    main()